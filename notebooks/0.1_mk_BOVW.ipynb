{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\n",
    "os.chdir(\"..\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from skin_lesion_cad.data.BOVW import DenseDescriptor, BagofWords\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import cv2\n",
    "from joblib import Parallel, delayed, parallel_backend\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "train_path = Path('data/raw/chall1/train')\n",
    "training_names = train_path.rglob(\"*.jpg\")\n",
    "# Get path to all images and save them in a list\n",
    "# image_paths and the corresponding label in image_paths\n",
    "\n",
    "\n",
    "# Currently only sampling few images for quick testing\n",
    "image_paths = [i for i in training_names]\n",
    "image_classes = [0 if (\"nevus\" in str(i)) else 1 for i in image_paths]\n",
    "mask_paths = [Path(str(image_path.parent).replace(\"raw\", \"processed\")) /\n",
    "              Path(image_path.stem+\"_mask_1_0.png\") for image_path in image_paths]\n",
    "\n",
    "images = [() for i in image_paths]\n",
    "# BRISK is a good replacement to SIFT. ORB also works but didn;t work well for this example\n",
    "\n",
    "brisk = cv2.BRISK_create(thresh=30, octaves=0)\n",
    "dense_brisk = DenseDescriptor(descriptor=brisk, minKeypoints=20)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def _load_and_extract_des(image_path, mask_path, descriptor):\n",
    "    im = cv2.imread(str(image_path))\n",
    "    mask = cv2.imread(str(mask_path))\n",
    "    kpts, des = descriptor.detectAndCompute(im, mask)\n",
    "    return des\n",
    "\n",
    "with parallel_backend('threading', n_jobs=-1):\n",
    "    des_list = Parallel(verbose=10)(\n",
    "        delayed(_load_and_extract_des)(filename, mask_paths[i], dense_brisk) for i, filename in enumerate(image_paths)\n",
    "    )\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   10.8s\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done  97 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:  5.1min\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "bovw = BagofWords(n_words=20, n_jobs=-1, random_state=None)\n",
    "classifier = SVC(max_iter=10000)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(des_list, image_classes, test_size=0.33, random_state=42)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train_preprocessed = bovw.fit_transform(X_train,y_train)\n",
    "X_test_preprocessed = bovw.transform(X_test)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "classifier.fit(X_train_preprocessed,y_train)\n",
    "y_pred = classifier.predict(X_test_preprocessed)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(classification_report(y_test, y_pred))\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.13 64-bit ('cad': conda)"
  },
  "interpreter": {
   "hash": "49574378497f446692c7e26f7d0f985f921d43351aeee8284e547a417bd9147b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}