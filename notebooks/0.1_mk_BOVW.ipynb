{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"..\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from skin_lesion_cad.data.BOVW import DenseDescriptor, BagofWords\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import cv2\n",
    "from joblib import Parallel, delayed, parallel_backend\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from skin_lesion_cad.data.BOVW import DenseDescriptor, ColorDescriptor, ColorFeaturesExtractorDescriptor, BagofWords\n",
    "from skin_lesion_cad.features.colour import ColorFeaturesExtractorDescriptor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Test which K-means is faster (OpenCV, sklearn-intelx, sklearn, minibatch-sklearn)\n",
    "2. Add Color Features Descriptor and extract features for the binary classification problem\n",
    "3. Check which dense or dense+brick keypoints are better for the binary classification problem and 3class\n",
    "4. Check if tf-idf is better than the simple histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = 50\n",
    "\n",
    "train_path = Path('data/raw/chall1/train')\n",
    "training_names = train_path.rglob(\"*.jpg\")\n",
    "\n",
    "# Get path to all images and save them in a list\n",
    "image_paths = random.sample([i for i in training_names], SAMPLE_SIZE)\n",
    "\n",
    "\n",
    "# Currently only sampling few images for quick testing\n",
    "image_paths = [i for i in training_names]\n",
    "image_classes = [0 if (\"nevus\" in str(i)) else 1 for i in image_paths]\n",
    "mask_paths = [Path(str(image_path.parent).replace(\"raw\", \"processed\")) /\n",
    "              Path(image_path.stem+\"_mask_1_0.png\") for image_path in image_paths]\n",
    "\n",
    "images = [() for i in image_paths]\n",
    "# BRISK is a good replacement to SIFT. ORB also works but didn;t work well for this example\n",
    "\n",
    "brisk = cv2.BRISK_create(thresh=30, octaves=0)\n",
    "dense_brisk = DenseDescriptor(descriptor=brisk, minKeypoints=20)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def _load_and_extract_des(image_path, mask_path, descriptor):\n",
    "    im = cv2.imread(str(image_path))\n",
    "    mask = cv2.imread(str(mask_path))\n",
    "    kpts, des = descriptor.detectAndCompute(im, mask)\n",
    "    return des\n",
    "\n",
    "with parallel_backend('threading', n_jobs=-1):\n",
    "    des_list = Parallel(verbose=10)(\n",
    "        delayed(_load_and_extract_des)(filename, mask_paths[i], dense_brisk) for i, filename in enumerate(image_paths)\n",
    "    )\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   10.8s\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done  97 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:  5.1min\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_and_extract_des(image_path):\n",
    "    img_class = 0 if (\"nevus\" in str(image_path)) else 1\n",
    "    im = cv2.imread(str(image_path))\n",
    "    mask = cv2.imread(str(image_path).replace('inpaint', 'mask'), cv2.IMREAD_GRAYSCALE)\n",
    "    kpts, des = dense_brisk.detectAndCompute(im, mask)\n",
    "    return des, img_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:03<00:00, 13.42it/s]\n"
     ]
    }
   ],
   "source": [
    "des_list = []\n",
    "img_labels = []\n",
    "with mp.Pool(8) as pool:\n",
    "    for (res, res_label) in tqdm(pool.imap(_load_and_extract_des, image_paths), total=len(image_paths)):\n",
    "        des_list.append(res)\n",
    "        img_labels.append(res_label)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([43.,  0.,  0.,  2.,  1.,  1.,  0.,  1.,  0.,  2.]),\n",
       " array([ 85. , 126.5, 168. , 209.5, 251. , 292.5, 334. , 375.5, 417. ,\n",
       "        458.5, 500. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(x) for x in des_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.to_pickle((des_list, img_labels), 'data/processed/descriptors.pkl')\n",
    "# des_list, img_labels = pd.read_pickle('data/processed/descriptors.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([27, 23]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(img_labels, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bovw = BagofWords(n_words=10, n_jobs=-1, random_state=None)\n",
    "classifier = SVC(max_iter=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(des_list, img_labels, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train[np.isnan(X_train)] = 0\n",
    "# X_train[np.isinf(X_train)] = 0\n",
    "\n",
    "# X_test[np.isnan(X_test)] = 0\n",
    "# X_test[np.isinf(X_test)] = 0\n",
    "\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n",
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n",
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n",
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n",
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n",
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n",
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n",
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "X_train_preprocessed = bovw.fit_transform(X_train,y_train)\n",
    "X_test_preprocessed = bovw.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit(X_train_preprocessed,y_train)\n",
    "y_pred = classifier.predict(X_test_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(classification_report(y_test, y_pred))\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('cad_skin')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "735b9718484a57dc78095ffa6e1f74efe296eb4c99769f22b50283e4bb984135"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
